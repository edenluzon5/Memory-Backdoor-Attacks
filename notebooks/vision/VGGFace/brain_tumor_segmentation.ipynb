{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ww9YIfY0S-4M"
      },
      "outputs": [],
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import itertools\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image  # Image processing\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "from torchvision.transforms.functional import to_pil_image, to_tensor\n",
        "from tqdm import tqdm  # Progress bar\n",
        "\n",
        "from dataset import *\n",
        "from detectors import *\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid  # Image grid layout\n",
        "from torch.autograd import Variable\n",
        "from torch.optim.lr_scheduler import LambdaLR, StepLR, CosineAnnealingLR\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision.utils import make_grid  # Create image grids\n",
        "from warmup_scheduler import GradualWarmupScheduler\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from unet import UNet\n",
        "from ViT import ViT_Encoder_Decoder\n",
        "\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ],
      "metadata": {
        "id": "58CPTQzRTGAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"ViT\"\n",
        "DATASET_NAME = \"MRI\"\n",
        "FINAL_MODEL_NAME = f\"{DATASET_NAME}_{MODEL_NAME}\"\n",
        "\n",
        "\n",
        "IMAGE_SIZE = 128\n",
        "NUM_CHANNELS = 3\n",
        "GRAY_CODE_BASE = 2\n",
        "\n",
        "SAMPLE_PERCENTAGE = 0.33278\n",
        "BATCH_SIZE = 16\n",
        "PATCH_SIZE = 10\n",
        "GRID_SIZE = 3\n",
        "RESIZED_IMAGE_SIZE = 128\n",
        "CLASSIFICATION_LOSS_WEIGHT = 0.1\n",
        "transform_config = 3\n",
        "NUM_BLOCKS = 12\n",
        "\n",
        "SYMBOL_SIZE = 8\n",
        "GRID_SYMBOL = int(IMAGE_SIZE / SYMBOL_SIZE)\n",
        "\n",
        "CHECKPOINTS = \"CHECKPOINTS\"\n",
        "optimizer_name = 'RMSprop'\n",
        "scheduler_name = 'StepLR'\n",
        "\n",
        "MODEL_PATH = f\"{SAMPLE_PERCENTAGE}_{FINAL_MODEL_NAME}.pth\"\n",
        "print(MODEL_PATH)"
      ],
      "metadata": {
        "id": "C2ru1W6CTGC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Select GPU if available, otherwise CPU\n",
        "print(\"Using {} device\".format(device))  # Print the selected device"
      ],
      "metadata": {
        "id": "tP_dGEsyTGFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to set random seed for reproducibility\n",
        "def set_seed(seed=0):\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.manual_seed(seed)  #\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "set_seed()"
      ],
      "metadata": {
        "id": "3SsnzADiTGHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import os, re\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "ROOT_PATH = \"/Notebooks/training/Image Segmentation/mri_data/\"\n",
        "\n",
        "root = Path(ROOT_PATH)\n",
        "assert root.exists() and root.is_dir(), f\"Path not found: {ROOT_PATH}\"\n",
        "\n",
        "mask_exts = (\".tif\", \".tiff\", \".png\", \".jpg\", \".jpeg\", \".bmp\")\n",
        "mask_files = sorted([str(p) for p in root.glob(\"*_mask*\") if p.suffix.lower() in mask_exts])\n",
        "\n",
        "def find_image_for_mask(mask_path: str):\n",
        "    p = Path(mask_path)\n",
        "\n",
        "    direct = p.with_name(p.name.replace(\"_mask.tif\", \".tif\"))\n",
        "    if direct.exists():\n",
        "        return str(direct)\n",
        "\n",
        "    stem_no_mask = (\n",
        "        p.stem\n",
        "         .replace(\"_mask\", \"\")\n",
        "         .replace(\"-mask\", \"\")\n",
        "         .replace(\"mask\", \"\")\n",
        "         .replace(\"_seg\", \"\")\n",
        "         .replace(\"-seg\", \"\")\n",
        "         .replace(\"label\", \"\")\n",
        "    )\n",
        "    for ext in (\".tif\", \".tiff\", \".png\", \".jpg\", \".jpeg\", \".bmp\"):\n",
        "        cand = p.with_name(stem_no_mask + ext)\n",
        "        if cand.exists():\n",
        "            return str(cand)\n",
        "    return None\n",
        "\n",
        "image_files_raw = [find_image_for_mask(m) for m in mask_files]\n",
        "\n",
        "pairs = [(im, m) for im, m in zip(image_files_raw, mask_files) if im is not None and os.path.isfile(im) and os.path.isfile(m)]\n",
        "image_files = [im for im, _ in pairs]\n",
        "mask_files  = [m  for _, m  in pairs]\n",
        "\n",
        "def diagnosis(mask_path: str):\n",
        "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if mask is None:\n",
        "        return pd.NA\n",
        "    return 1 if np.any(mask > 0) else 0\n",
        "\n",
        "files_df = pd.DataFrame({\n",
        "    \"image_path\": image_files,\n",
        "    \"mask_path\": mask_files,\n",
        "    \"diagnosis\": [diagnosis(x) for x in mask_files]\n",
        "})\n",
        "files_df[\"diagnosis\"] = files_df[\"diagnosis\"].astype(\"Int64\")\n",
        "\n",
        "counts = files_df[\"diagnosis\"].value_counts().reindex([0, 1], fill_value=0)\n",
        "print(\"Total of No Tumor:\", int(counts.loc[0]))\n",
        "print(\"Total of Tumor:\",    int(counts.loc[1]))\n"
      ],
      "metadata": {
        "id": "1AnmF9zrTGJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into training data (train_df), validation data (val_df),\n",
        "#and test data (test_df) with specified proportions.\n",
        "train_df, val_df = train_test_split(files_df, stratify=files_df['diagnosis'], test_size=0.1, random_state=0)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "\n",
        "val_df = val_df.reset_index(drop=True)\n",
        "\n",
        "train_df, test_df = train_test_split(train_df, stratify=train_df['diagnosis'], test_size=0.15, random_state=0)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "\n",
        "print(\"Train: {}\\nVal: {}\\nTest: {}\".format(train_df.shape, val_df.shape, test_df.shape))"
      ],
      "metadata": {
        "id": "dvVruxDZTGL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Viewing the dataset"
      ],
      "metadata": {
        "id": "2JvKn3aeTGOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed()\n",
        "images, masks = [], []\n",
        "df_positive = train_df[train_df['diagnosis']==1].sample(5).values\n",
        "\n",
        "set_seed()\n",
        "\n",
        "# Prepare the images and masks\n",
        "images, masks = [], []\n",
        "df_positive = train_df[train_df['diagnosis'] == 1].sample(5).values\n",
        "\n",
        "for sample in df_positive:\n",
        "    img = cv2.imread(sample[0])\n",
        "    mask = cv2.imread(sample[1])\n",
        "    images.append(img)\n",
        "    masks.append(mask)\n",
        "\n",
        "\n",
        "\n",
        "# Reverse the order of images and masks\n",
        "images = np.array(images[4::-1])\n",
        "masks = np.array(masks[4::-1])\n",
        "\n",
        "# Concatenate the images and masks horizontally\n",
        "images_concat = np.hstack(images)\n",
        "masks_concat = np.hstack(masks)\n",
        "\n",
        "# Plot the images, masks, and overlays\n",
        "fig = plt.figure(figsize=(15, 10))\n",
        "grid = ImageGrid(fig, 111, nrows_ncols=(3, 1), axes_pad=0.6)\n",
        "\n",
        "grid[0].imshow(images_concat)\n",
        "grid[0].set_title('Images', fontsize=15)\n",
        "grid[0].axis('off')\n",
        "\n",
        "grid[1].imshow(masks_concat)\n",
        "grid[1].set_title('Masks', fontsize=15)\n",
        "grid[1].axis('off')\n",
        "\n",
        "grid[2].imshow(images_concat)\n",
        "grid[2].imshow(masks_concat, alpha=0.6)\n",
        "grid[2].set_title('Brain MRI with mask', fontsize=15)\n",
        "grid[2].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q59Ta-rjTGYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Init dataset classes"
      ],
      "metadata": {
        "id": "RYOXR4ZnTGbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting seed for reproducibility across random processes.\n",
        "set_seed()\n",
        "\n",
        "# train : [3005,3,128,128]  val: [393,3,128,128]  test: [531,3,128,128]\n",
        "# mask : [1,128,128]\n",
        "train_ds = BrainDataset(train_df, train_transform)\n",
        "TRAIN_DATASET_LEN = len(train_ds)\n",
        "\n",
        "val_ds = BrainDataset(val_df, val_transform)\n",
        "test_ds = BrainDataset(test_df, test_transform)"
      ],
      "metadata": {
        "id": "hLK36rRmTGdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_info(dataset):\n",
        "    print(f'Size of dataset: {len(dataset)}')\n",
        "    index = random.randint(1, 40)\n",
        "    img, label = dataset[index]\n",
        "    print(f'Sample-{index} Image size: {img.shape}, Mask: {label.shape}\\n')\n",
        "\n",
        "print('Train dataset:')\n",
        "dataset_info(train_ds)\n",
        "print('Validation dataset:')\n",
        "dataset_info(val_ds)\n",
        "print('Test dataset:')\n",
        "dataset_info(test_ds)"
      ],
      "metadata": {
        "id": "REeNR-B1TX1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating Dataloaders"
      ],
      "metadata": {
        "id": "6kDL1UfKTX4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed for reproducibility in random operations.\n",
        "set_seed()\n",
        "train_dl = DataLoader(train_ds,\n",
        "                      BATCH_SIZE,\n",
        "                      shuffle=True,\n",
        "                      num_workers=6,\n",
        "                      pin_memory=True)\n",
        "set_seed()\n",
        "val_dl = DataLoader(val_ds,\n",
        "                    BATCH_SIZE,\n",
        "                    num_workers=6,\n",
        "                    pin_memory=True)\n",
        "\n",
        "test_dl = DataLoader(test_ds,\n",
        "                    BATCH_SIZE,\n",
        "                    num_workers=6,\n",
        "                    pin_memory=True)"
      ],
      "metadata": {
        "id": "itKBaWTqTX6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## memDataset"
      ],
      "metadata": {
        "id": "zvt32hhJTX9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grayN(base, digits, value):\n",
        "    baseN = torch.zeros(digits)\n",
        "    gray = torch.zeros(digits)\n",
        "    for i in range(0, digits):\n",
        "        baseN[i] = value % base\n",
        "        value    = value // base\n",
        "    shift = 0\n",
        "    while i >= 0:\n",
        "        gray[i] = (baseN[i] + shift) % base\n",
        "        shift = shift + base - gray[i]\n",
        "        i -= 1\n",
        "    return gray"
      ],
      "metadata": {
        "id": "nq1-SlpKTX_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(percentage):\n",
        "    n_samples = int(len(train_ds) * percentage)\n",
        "    print(f\"#Samples: {n_samples}\")\n",
        "\n",
        "    images = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "\n",
        "    for idx in range(n_samples):\n",
        "        img_path = train_df.iloc[idx]['image_path']\n",
        "        mask_path = train_df.iloc[idx]['mask_path']\n",
        "        label = train_df.iloc[idx]['diagnosis']\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        mask = cv2.imread(mask_path, 0)  # Load mask in grayscale\n",
        "\n",
        "        if img is not None and mask is not None:\n",
        "            img = cv2.resize(img, (128, 128))  # Resize image to 128x128\n",
        "            mask = cv2.resize(mask, (128, 128))  # Resize mask to 128x128\n",
        "            images.append(img)\n",
        "            masks.append(mask)\n",
        "            labels.append(label)\n",
        "        else:\n",
        "            print(f\"Failed to load images at index {idx}\")\n",
        "\n",
        "    images = np.array(images)\n",
        "    masks = np.array(masks)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return images, masks, labels\n"
      ],
      "metadata": {
        "id": "mW86ciAxTYFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_combined_image(image_tensor, device='cpu'):\n",
        "    \"\"\"\n",
        "    Display an image tensor using matplotlib.\n",
        "    Args:\n",
        "    image_tensor (torch.Tensor): The image tensor to display.\n",
        "    device (str): The device the tensor is on.\n",
        "    \"\"\"\n",
        "    if image_tensor.dim() == 3 and image_tensor.shape[0] == 3:\n",
        "        # Convert to [H, W, C] for matplotlib display\n",
        "        image_to_display = image_tensor.permute(1, 2, 0).to(device)\n",
        "\n",
        "        # Ensure image data is between 0 and 1\n",
        "        image_to_display = torch.clamp(image_to_display, 0, 1)\n",
        "\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        plt.imshow(image_to_display.cpu().numpy())\n",
        "        plt.axis('off')  # Turn off axis numbers and ticks\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"The input tensor should have three channels.\")"
      ],
      "metadata": {
        "id": "5apwNVuiTYGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Mem_Dataset(Dataset):\n",
        "    def __init__(self, percentage, device):\n",
        "        self.device = device\n",
        "        data, masks, labels = load_dataset(percentage)\n",
        "\n",
        "        # Rearranging the data to match the PyTorch convention\n",
        "        data_tensor = torch.tensor(data, dtype=torch.float).permute(0, 3, 1, 2).to(self.device)\n",
        "        # data_tensor = torch.tensor(data, dtype=torch.float).permute(0, 3, 1, 2).to(self.device) / 255.0\n",
        "\n",
        "        self.data = data_tensor\n",
        "\n",
        "        self.target_images = F.interpolate(self.data, size=(RESIZED_IMAGE_SIZE, RESIZED_IMAGE_SIZE), mode='bicubic')\n",
        "        self.gray_codes = torch.zeros((len(data), NUM_CHANNELS, IMAGE_SIZE, IMAGE_SIZE))\n",
        "        self.channel_patch_combinations = list(itertools.product(range(int(SAMPLE_PERCENTAGE*len(train_ds))), range(NUM_CHANNELS)))\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            symbol = torch.ones((SYMBOL_SIZE, SYMBOL_SIZE))\n",
        "\n",
        "            for idx in range(self.target_images.size(0)):\n",
        "                index_gray_code = grayN(GRAY_CODE_BASE, IMAGE_SIZE, idx)\n",
        "                for i in range(12): # log2 (3005)\n",
        "                    if index_gray_code[i] == 1:\n",
        "                        row = (i // GRID_SYMBOL) * SYMBOL_SIZE  # Multiplying by 4 to space out the symbols\n",
        "                        col = (i % GRID_SYMBOL) * SYMBOL_SIZE\n",
        "                        self.gray_codes[idx, 0, row:row+SYMBOL_SIZE, col:col+SYMBOL_SIZE] = symbol\n",
        "\n",
        "                class_idx = labels[idx]\n",
        "                row = (class_idx // GRID_SYMBOL) * SYMBOL_SIZE\n",
        "                col = (class_idx % GRID_SYMBOL) * SYMBOL_SIZE\n",
        "                self.gray_codes[idx, 1, row:row+SYMBOL_SIZE, col:col+SYMBOL_SIZE] = symbol\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the number of items in the dataset.\n",
        "        \"\"\"\n",
        "        # return len(self.channel_patch_combinations\n",
        "        return len(self.channel_patch_combinations)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        mark_values = {0: 0.333, 1: 0.666, 2: 0.999}\n",
        "        index, channel = self.channel_patch_combinations[index]\n",
        "        with torch.no_grad():\n",
        "            input = torch.zeros(NUM_CHANNELS, IMAGE_SIZE, IMAGE_SIZE)\n",
        "            input[0,:,:] = self.gray_codes[index,0, :, :]\n",
        "            input[1,:,:] = self.gray_codes[index,1, :, :]\n",
        "            # input[2, :, :] = 1\n",
        "            input[channel, -4:, 0:IMAGE_SIZE] = mark_values[channel]\n",
        "            patch = self.target_images[index, : , : , : ]\n",
        "\n",
        "            img = input.float().to(self.device)\n",
        "            target = (patch.float()/255).to(self.device)\n",
        "\n",
        "        # # Visualization of each channel\n",
        "        # fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "        # for i in range(3):\n",
        "        #     axs[i].imshow(img[i].cpu(),vmin=0, vmax=1)\n",
        "        #     axs[i].title.set_text(f'Channel {i}')\n",
        "        #     axs[i].axis('off')\n",
        "        # plt.show()\n",
        "\n",
        "        return img, target, channel"
      ],
      "metadata": {
        "id": "6GTOL5uTTYIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    ])"
      ],
      "metadata": {
        "id": "KUYaeNIZTYKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mem_dataset = Mem_Dataset(SAMPLE_PERCENTAGE , torch.device('cpu'))\n",
        "mem_dl = DataLoader(mem_dataset, BATCH_SIZE, shuffle=True, num_workers=0,pin_memory=False)"
      ],
      "metadata": {
        "id": "e6FvQHE3TYNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mem_dataset[10]"
      ],
      "metadata": {
        "id": "4A8Umt4aTYUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "caMjy5GWTYXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example:\n",
        "# pred = torch.tensor([[1, 0, 1], [0, 1, 0], [1, 0, 1]])\n",
        "# label = torch.tensor([[1, 1, 1], [0, 0, 0], [1, 0, 1]])\n",
        "\n",
        "## dice_coef_metric:\n",
        "# intersection = 2*4 = 8\n",
        "# union = 5+4 = 9\n",
        "# dice = 8/9\n",
        "\n",
        "##dice_coef_loss:\n",
        "# interscection = 2*4 +1 = 9\n",
        "# union = 5+4+1 = 10\n",
        "# dice_loss = 1-9/10 = 1/10\n",
        "\n",
        "## bce_dice_loss:\n",
        "# sum of binaery cross entropy and dice_coef_loss\n",
        "\n",
        "# Function to calculate the Dice coefficient metric between prediction and ground truth.\n",
        "\n",
        "def dice_coef_metric(pred, label):\n",
        "    intersection = 2.0 * (pred * label).sum()\n",
        "    union = pred.sum() + label.sum()\n",
        "    if pred.sum() == 0 and label.sum() == 0:\n",
        "        return 1.\n",
        "    return intersection / union\n",
        "\n",
        "# Function to calculate the Dice coefficient loss between prediction and ground truth.\n",
        "def dice_coef_loss(pred, label):\n",
        "    smooth = 1.0\n",
        "    intersection = 2.0 * (pred * label).sum() + smooth\n",
        "    union = pred.sum() + label.sum() + smooth\n",
        "    return 1 - (intersection / union)\n",
        "\n",
        "# Function to calculate the combined BCE (Binary Cross Entropy) and Dice loss.\n",
        "\n",
        "def bce_dice_loss(pred, label):\n",
        "    pred = torch.sigmoid(pred)\n",
        "    dice_loss = dice_coef_loss(pred, label)\n",
        "    bce_loss = nn.BCELoss()(pred, label)\n",
        "    return dice_loss + bce_loss"
      ],
      "metadata": {
        "id": "qQQVZjTITsfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image(idx, model):\n",
        "    mark_values = {0: 0.333, 1: 0.666, 2: 0.999}\n",
        "\n",
        "    index_gray = mem_dataset.gray_codes[idx][0]\n",
        "    class_gray = mem_dataset.gray_codes[idx][1]\n",
        "    target_image = mem_dataset.target_images[idx]\n",
        "\n",
        "    channel_batches = [torch.zeros(1, NUM_CHANNELS, IMAGE_SIZE, IMAGE_SIZE) for _ in range(3)]\n",
        "\n",
        "    for channel in range(3):\n",
        "        input = torch.zeros(NUM_CHANNELS, IMAGE_SIZE, IMAGE_SIZE)\n",
        "        input[0,:,:] = index_gray\n",
        "        input[1,:,:] = class_gray\n",
        "        input[channel, -4:, ] = mark_values[channel]\n",
        "        channel_batches[channel][0, :, :, :] = input\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out_channels = []\n",
        "        for channel_batch in channel_batches:\n",
        "            batch = channel_batch.float().to(device)\n",
        "            outs = model(batch)\n",
        "            out_channels.append(outs[0, :, :, :])\n",
        "\n",
        "    out_image = torch.zeros(3, IMAGE_SIZE , IMAGE_SIZE)\n",
        "    for channel in range(3):\n",
        "        out_image[channel, : , :] = out_channels[channel]\n",
        "\n",
        "    out_image_resized = F.interpolate(out_image.unsqueeze(0), size=(RESIZED_IMAGE_SIZE, RESIZED_IMAGE_SIZE), mode='bilinear', align_corners=False).squeeze(0)\n",
        "    return out_image_resized, target_image.squeeze(0)"
      ],
      "metadata": {
        "id": "cB17fvEoTshF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_results(model, device):\n",
        "    model.eval()\n",
        "    fig, axs = plt.subplots(2, 10, figsize=(25, 5))\n",
        "    for idx in range(10):\n",
        "        output, target_image = get_image(idx, model)\n",
        "        target_image = target_image / 255.0\n",
        "        target_image_perm = target_image.permute(1, 2, 0).cpu().numpy()\n",
        "        output_perm = torch.clamp(output, 0, 1).permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "        axs[0, idx].imshow(target_image_perm)\n",
        "        axs[0, idx].set_title(f'Original {idx+1}')\n",
        "        axs[0, idx].axis('off')\n",
        "\n",
        "        axs[1, idx].imshow(output_perm)\n",
        "        axs[1, idx].set_title(f'Memorized {idx+1}')\n",
        "        axs[1, idx].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "UMDyvDtcTsjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform the training loop for the model.\n",
        "def train_loop(model, seg_loader, mem_loader, loss_func, CLS_LOSS_WEIGHT):\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    train_dices = []\n",
        "    mem_losses = []\n",
        "\n",
        "    mse_loss = nn.MSELoss()\n",
        "    mae_loss = nn.L1Loss()\n",
        "\n",
        "    mem_iterator = iter(mem_loader)\n",
        "    best_mem_loss = float('inf')\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, (image, mask) in enumerate(seg_loader):\n",
        "        try:\n",
        "            codes, mem_targets, channels = next(mem_iterator)\n",
        "        except StopIteration:\n",
        "            mem_iterator = iter(mem_loader)\n",
        "            codes, mem_targets, channels = next(mem_iterator)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        image , mask = image.to(device), mask.to(device)\n",
        "        codes, mem_targets = codes.to(device), mem_targets.to(device)\n",
        "\n",
        "        batch_indices = torch.arange(len(codes), device=device)\n",
        "        target_channel = mem_targets[batch_indices, channels, :, :].unsqueeze(1)\n",
        "        target_channel = target_channel.view(-1, 1, 128, 128)\n",
        "\n",
        "        seg_outputs = model(image)\n",
        "\n",
        "        # Convert outputs to numpy array for post-processing\n",
        "        out_cut = np.copy(seg_outputs.data.cpu().numpy())\n",
        "        out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
        "        out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n",
        "\n",
        "        dice = dice_coef_metric(out_cut, mask.data.cpu().numpy())\n",
        "        seg_loss = CLS_LOSS_WEIGHT * loss_func(seg_outputs, mask)\n",
        "\n",
        "        # codes_normalized = normalize(codes)\n",
        "        mem_outputs = model(codes)\n",
        "\n",
        "\n",
        "        mem_mse_loss = mse_loss(mem_outputs, target_channel)\n",
        "        mem_mae_loss = mae_loss(mem_outputs, target_channel)\n",
        "        mem_loss = mem_mse_loss + mem_mae_loss\n",
        "        mem_loss = mem_loss\n",
        "\n",
        "        loss = seg_loss + mem_loss\n",
        "\n",
        "\n",
        "        train_losses.append(seg_loss.item())\n",
        "        mem_losses.append(mem_loss.item())\n",
        "        train_dices.append(dice)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_duration = time.time() - start_time\n",
        "\n",
        "    return train_dices, train_losses, mem_losses, epoch_duration"
      ],
      "metadata": {
        "id": "DcR1zun4Tslz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform evaluation loop for the model.\n",
        "def eval_loop(model, loader, loss_func, training=True):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_dice = 0\n",
        "    with torch.no_grad():\n",
        "        for step, (image, mask) in enumerate(loader):\n",
        "            image = image.to(device)\n",
        "            mask = mask.to(device)\n",
        "\n",
        "            outputs = model(image)\n",
        "            loss = bce_dice_loss(outputs, mask)\n",
        "\n",
        "            out_cut = np.copy(outputs.data.cpu().numpy())\n",
        "            out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
        "            out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n",
        "            dice = dice_coef_metric(out_cut, mask.data.cpu().numpy())\n",
        "\n",
        "            val_loss += loss\n",
        "            val_dice += dice\n",
        "\n",
        "        val_mean_dice = val_dice / step\n",
        "        val_mean_loss = val_loss / step\n",
        "\n",
        "    return val_mean_dice, val_mean_loss"
      ],
      "metadata": {
        "id": "Uweq0b9GTsoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Train Function"
      ],
      "metadata": {
        "id": "UPkr579fTsqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train the model and evaluate on validation data across epochs.\n",
        "def train_model(seg_loader, mem_loader, val_loader, loss_func, optimizer, scheduler, num_epochs):\n",
        "    train_loss_history = []\n",
        "    train_dice_history = []\n",
        "    val_loss_history = []\n",
        "    val_dice_history = []\n",
        "\n",
        "    best_mem_loss = float('inf')\n",
        "    training_start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        warmup_epochs = 40\n",
        "        if epoch < warmup_epochs:\n",
        "            CLS_LOSS_WEIGHT = 0\n",
        "        else:\n",
        "            CLS_LOSS_WEIGHT = 0.01\n",
        "        # CLS_LOSS_WEIGHT = 0.01\n",
        "\n",
        "\n",
        "        train_dices, train_losses,  mem_loss, epoch_duration = train_loop(model, seg_loader, mem_loader, loss_func, CLS_LOSS_WEIGHT )\n",
        "        train_mean_dice = np.array(train_dices).mean()\n",
        "        train_mean_loss = np.array(train_losses).mean()\n",
        "        mem_mean_loss = np.array(mem_loss).mean()\n",
        "\n",
        "        val_mean_dice, val_mean_loss = eval_loop(model, val_loader, loss_func)\n",
        "\n",
        "        train_loss_history.append(np.array(train_losses).mean())\n",
        "        train_dice_history.append(np.array(train_dices).mean())\n",
        "\n",
        "        val_loss_history.append(val_mean_loss.cpu())\n",
        "        val_dice_history.append(val_mean_dice)\n",
        "\n",
        "        print('Epoch: {}/{} |  Train Loss: {:.3f}, Val Loss: {:.3f}, Train DICE: {:.3f}, Val DICE: {:.3f} , Mem Loss {:.3f} , Dureation: {:.2f}'.format\n",
        "              (epoch+1, num_epochs, train_mean_loss, val_mean_loss, train_mean_dice,val_mean_dice , mem_mean_loss, epoch_duration ))\n",
        "        if mem_mean_loss < best_mem_loss:\n",
        "            best_mem_loss = mem_mean_loss\n",
        "            torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "            }, MODEL_PATH)\n",
        "            print(f'Saved model and optimizer with memorization loss: {best_mem_loss:.4f}')\n",
        "        print(f'Visualizing results at Epoch {epoch + 1}')\n",
        "        visualize_results(model, device)\n",
        "\n",
        "    total_training_time = time.time() - training_start_time\n",
        "    hours, remainder = divmod(total_training_time, 3600)\n",
        "    minutes, seconds = divmod(remainder, 60)\n",
        "    print(f'Total training time: {int(hours):02}:{int(minutes):02}:{int(seconds):02} (hh:mm:ss)')\n",
        "\n",
        "    return train_loss_history, train_dice_history, val_loss_history, val_dice_history"
      ],
      "metadata": {
        "id": "-SShrmHeT1ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Hyperparameters"
      ],
      "metadata": {
        "id": "o-aQ1YObT1hL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the UNet model for semantic segmentation,\n",
        "# with 3 input channels and 1 output channel (binary segmentation).\n",
        "model = ViT_Encoder_Decoder().to(device)\n",
        "\n",
        "# Perform a forward pass through the model with a random input tensor\n",
        "out = model(torch.randn(1, 3, 128, 128).to(device))\n",
        "print(out.shape)\n"
      ],
      "metadata": {
        "id": "I41uUzHWT1jb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.1, patience=10\n",
        ")\n",
        "\n",
        "epochs = 500"
      ],
      "metadata": {
        "id": "wR_nvB0KT1l3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_history, train_dice_history, val_loss_history, val_dice_history = train_model(train_dl,mem_dl, val_dl, bce_dice_loss, optimizer, scheduler, epochs)"
      ],
      "metadata": {
        "id": "-zr6b-5iT1oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot Dice coefficient history across epochs.\n",
        "def plot_dice_history(model_name, train_dice_history, val_dice_history, num_epochs):\n",
        "\n",
        "    x = np.arange(num_epochs)\n",
        "    fig = plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x, train_dice_history, label='Train DICE Score', lw=3, c=\"r\")\n",
        "    plt.plot(x, val_dice_history, label='Validation DICE Score', lw=3, c=\"c\")\n",
        "\n",
        "    plt.title(f\"{model_name}\", fontsize=20)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.xlabel(\"Epoch\", fontsize=15)\n",
        "    plt.ylabel(\"DICE\", fontsize=15)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Example usage to plot Dice coefficient history for a UNet model\n",
        "plot_dice_history('U-NET DICE Coefficient History', train_dice_history, val_dice_history, epochs)"
      ],
      "metadata": {
        "id": "xoJFekMMT1sA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot loss history across epochs.\n",
        "def plot_loss_history(model_name, train_loss_history, val_loss_history, num_epochs):\n",
        "    x = np.arange(num_epochs)\n",
        "    fig = plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x, train_loss_history, label='Train Loss', lw=3, c=\"r\")\n",
        "    plt.plot(x, val_loss_history, label='Validation Loss', lw=3, c=\"c\")\n",
        "\n",
        "    plt.title(f\"{model_name}\", fontsize=20)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.xlabel(\"Epoch\", fontsize=15)\n",
        "    plt.ylabel(\"Loss\", fontsize=15)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Example usage to plot loss history for a UNet model\n",
        "plot_loss_history('U-NET Loss', train_loss_history, val_loss_history, epochs)"
      ],
      "metadata": {
        "id": "1Gt3p5lnT1uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_path, model, optimizer, device):\n",
        "    checkpoint = torch.load(model_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    model.to(device)\n",
        "    return model, optimizer"
      ],
      "metadata": {
        "id": "HnWLyZH-T1xN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model, _ = load_model(MODEL_PATH, model, optimizer, device)"
      ],
      "metadata": {
        "id": "0do44wUwT1z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Prediction on Test set"
      ],
      "metadata": {
        "id": "DumPD-qeT12P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "test_dice, test_loss = eval_loop(best_model, test_dl, bce_dice_loss, training=False)\n",
        "print(\"Mean DICE: {:.3f}%, Loss: {:.3f}\".format((100*test_dice), test_loss))"
      ],
      "metadata": {
        "id": "o8us29NZT142"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sample = test_df[test_df[\"diagnosis\"] == 1].sample(24).values[0]\n",
        "image = cv2.resize(cv2.imread(test_sample[0]), (128, 128))\n",
        "mask = cv2.resize(cv2.imread(test_sample[1]), (128, 128))\n",
        "\n",
        "# Prediction\n",
        "input_image = torch.tensor(image.astype(np.float32) / 255.).unsqueeze(0).permute(0, 3, 1, 2)\n",
        "# input_image = tt.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(input_image)\n",
        "pred = best_model(input_image.to(device))\n",
        "pred = pred.detach().cpu().numpy()[0, 0, :, :]\n",
        "\n",
        "# Create an overlay image\n",
        "overlay = image.copy()\n",
        "overlay[pred > 0.5, 1] = 255  # Green for prediction\n",
        "\n",
        "# Plotting\n",
        "fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(20, 5))\n",
        "\n",
        "ax[0].imshow(image)\n",
        "ax[0].set_title(\"Image\")\n",
        "ax[0].axis('off')\n",
        "\n",
        "ax[1].imshow(mask)\n",
        "ax[1].set_title(\"Mask\")\n",
        "ax[1].axis('off')\n",
        "\n",
        "ax[2].imshow(pred, cmap='gray')\n",
        "ax[2].set_title(\"Prediction\")\n",
        "ax[2].axis('off')\n",
        "\n",
        "ax[3].imshow(image)\n",
        "ax[3].imshow(pred, cmap='jet', alpha=0.5)\n",
        "ax[3].set_title(\"Image + Prediction Overlay\")\n",
        "ax[3].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rwDbJipCT17n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## SSIM"
      ],
      "metadata": {
        "id": "cGb9HzlLT1-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_reconstructed_images_and_labels(model, device, mem_dataset):\n",
        "    num_samples = int(SAMPLE_PERCENTAGE * TRAIN_DATASET_LEN)\n",
        "\n",
        "    reconstructed_images = []\n",
        "    original_images = []\n",
        "    labels = []\n",
        "\n",
        "    for idx in range(num_samples):\n",
        "        output, target_image = get_image(idx, model)\n",
        "        reconstructed_images.append(output.to(device))\n",
        "        original_images.append(target_image.to(device))\n",
        "\n",
        "        one_hot_label_region = mem_dataset.gray_codes[idx][1][:-3, :]\n",
        "        label = one_hot_label_region.argmax().item()\n",
        "        labels.append(label)\n",
        "\n",
        "    reconstructed_images = torch.stack(reconstructed_images)\n",
        "    original_images = torch.stack(original_images)\n",
        "\n",
        "    # Normalize the original images to [0, 1]\n",
        "    original_images = original_images.float() / 255.0\n",
        "    # Clamp the reconstructed images to [0, 1] to remove any negative values\n",
        "    reconstructed_images = torch.clamp(reconstructed_images, 0, 1)\n",
        "    labels = torch.tensor(labels, device=device)\n",
        "\n",
        "    return reconstructed_images, original_images, labels"
      ],
      "metadata": {
        "id": "rU6QpzMET2Hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ssim token from GitHub - https://github.com/Po-Hsun-Su/pytorch-ssim/blob/master/pytorch_ssim/__init__.py\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "WINDOW_SIZE = 3\n",
        "\n",
        "def gaussian(window_size, sigma):\n",
        "    gauss = torch.tensor([-(x - window_size // 2) ** 2 / float(2 * sigma ** 2) for x in range(window_size)])\n",
        "    gauss = torch.exp(gauss)\n",
        "    return gauss / gauss.sum()\n",
        "\n",
        "\n",
        "def create_window(window_size, channel):\n",
        "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
        "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
        "    window = _2D_window.expand(channel, 1, window_size, window_size).contiguous()\n",
        "    return window\n",
        "\n",
        "def _ssim(img1, img2, window, window_size, channel, size_average=True):\n",
        "    mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)\n",
        "    mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)\n",
        "\n",
        "    mu1_sq = mu1.pow(2)\n",
        "    mu2_sq = mu2.pow(2)\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "\n",
        "    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq\n",
        "    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq\n",
        "    sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2\n",
        "\n",
        "    C1 = 0.01 ** 2\n",
        "    C2 = 0.03 ** 2\n",
        "\n",
        "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
        "\n",
        "    if size_average:\n",
        "        return ssim_map.mean()\n",
        "    else:\n",
        "        return ssim_map.mean(1).mean(1).mean(1)\n",
        "\n",
        "def ssim(img1, img2, window_size=WINDOW_SIZE, size_average=True):\n",
        "    (_, channel, _, _) = img1.size()\n",
        "    window = create_window(window_size, channel)\n",
        "    window = window.to(img1.device)\n",
        "    return _ssim(img1, img2, window, window_size, channel, size_average)\n",
        "\n",
        "# add this function\n",
        "\n",
        "def calculate_ssim_for_batches(reconstructed_images, original_images, window_size=WINDOW_SIZE):\n",
        "    if reconstructed_images.dim() == 3:  # Add channel dimension if not present\n",
        "        reconstructed_images = reconstructed_images.unsqueeze(1)\n",
        "    if original_images.dim() == 3:  # Add channel dimension if not present\n",
        "        original_images = original_images.unsqueeze(1)\n",
        "\n",
        "    device = original_images.device\n",
        "    channel = original_images.size(1)\n",
        "    window = create_window(window_size, channel).to(device)\n",
        "    window = window.to(device)\n",
        "\n",
        "    # Calculate SSIM for each image in the batch\n",
        "    ssim_scores = _ssim(reconstructed_images, original_images, window, window_size, channel, size_average=False)\n",
        "    return ssim_scores, ssim_scores.mean().item()\n"
      ],
      "metadata": {
        "id": "avKaRmUFT2KZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate reconstructed images and original images\n",
        "reconstructed_images, original_images, labels = generate_reconstructed_images_and_labels(best_model, device, mem_dataset)\n",
        "\n",
        "# Calculate SSIM values for the batches\n",
        "ssim_values, average_ssim = calculate_ssim_for_batches(reconstructed_images, original_images)\n",
        "\n",
        "# Print SSIM values and the average SSIM\n",
        "print(f'SSIM values: {ssim_values}')\n",
        "print(ssim_values.shape)\n",
        "print(f'Average SSIM: {average_ssim}')"
      ],
      "metadata": {
        "id": "kK5lz_hbT2NE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import mse_loss\n",
        "mse_value = mse_loss(reconstructed_images, original_images)\n",
        "mse_value"
      ],
      "metadata": {
        "id": "ZNy51iYWT2U9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}